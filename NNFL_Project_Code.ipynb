{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8KJ6MkAC2d1"
   },
   "source": [
    "NNFL ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNdhGk9VWXcn",
    "outputId": "eec5bdc5-bc44-4fb2-c9c5-ac007e3b0349"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzirspccVNgK",
    "outputId": "db666de8-9fb4-4edc-9e07-e0cf4c9738ea"
   },
   "outputs": [],
   "source": [
    "pip install -r lib/Mask_RCNN/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7l3RG7cELxM",
    "outputId": "d996b997-6a8d-4b66-b650-6621aa46855f"
   },
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow \n",
    "!pip install tensorflow==1.14\n",
    "\n",
    "!pip uninstall keras \n",
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOUaWPPVEUEY",
    "outputId": "15ff5882-0ca5-465f-badf-6edf2b93a108"
   },
   "outputs": [],
   "source": [
    "!pip install Keras-Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDxI6obwSKfF",
    "outputId": "c6a9be56-ab1e-4673-9daf-f265d3a675bf"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%load_ext line_profiler\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "sess_config = tf.compat.v1.ConfigProto()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "COCO_DATA = 'data/coco/'\n",
    "MASK_RCNN_MODEL_PATH = 'lib/Mask_RCNN/'\n",
    "\n",
    "if MASK_RCNN_MODEL_PATH not in sys.path:\n",
    "    sys.path.append(MASK_RCNN_MODEL_PATH)\n",
    "    \n",
    "from lib.Mask_RCNN.samples.coco import coco\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "    \n",
    "from lib import utils as siamese_utils\n",
    "from lib import model as siamese_model\n",
    "from lib import config as siamese_config\n",
    "   \n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import imgaug\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyX-KprST172",
    "outputId": "07d60c05-19c3-4dcc-8e0f-6d58e101468c"
   },
   "outputs": [],
   "source": [
    "# train_classes = coco_nopascal_classes\n",
    "train_classes = np.array(range(1,81))\n",
    "\n",
    "# Load COCO/val dataset\n",
    "coco_val = siamese_utils.IndexedCocoDataset()\n",
    "coco_object = coco_val.load_coco(COCO_DATA, \"val\", year=\"2017\", return_coco=True)\n",
    "coco_val.prepare()\n",
    "coco_val.build_indices()\n",
    "coco_val.ACTIVE_CLASSES = train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEMybx3zT5VN"
   },
   "outputs": [],
   "source": [
    "class SmallEvalConfig(siamese_config.Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'coco'\n",
    "    EXPERIMENT = 'evaluation'\n",
    "    CHECKPOINT_DIR = 'checkpoints/'\n",
    "    NUM_TARGETS = 1\n",
    "    \n",
    "class LargeEvalConfig(siamese_config.Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'coco'\n",
    "    EXPERIMENT = 'evaluation'\n",
    "    CHECKPOINT_DIR = 'checkpoints/'\n",
    "    NUM_TARGETS = 1\n",
    "    \n",
    "    # Large image sizes\n",
    "    TARGET_MAX_DIM = 192\n",
    "    TARGET_MIN_DIM = 150\n",
    "    IMAGE_MIN_DIM = 800\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    # Large model size\n",
    "    FPN_CLASSIF_FC_LAYERS_SIZE = 1024\n",
    "    FPN_FEATUREMAPS = 256\n",
    "    # Large number of rois at all stages\n",
    "    RPN_ANCHOR_STRIDE = 1\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
    "    POST_NMS_ROIS_TRAINING = 2000\n",
    "    POST_NMS_ROIS_INFERENCE = 1000\n",
    "    TRAIN_ROIS_PER_IMAGE = 200\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    MAX_GT_INSTANCES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8EB8IQJMT8fl",
    "outputId": "1e25135f-9e29-4a14-c816-4e0a4364a65f"
   },
   "outputs": [],
   "source": [
    "# The small model trains on a single GPU and runs much faster.\n",
    "# The large model is the same we used in our experiments but needs multiple GPUs and more time for training.\n",
    "model_size = 'small' # or 'large'\n",
    "\n",
    "if model_size == 'small':\n",
    "    config = SmallEvalConfig()\n",
    "elif model_size == 'large':\n",
    "    config = LargeEvalConfig()\n",
    "    \n",
    "config.display()\n",
    "\n",
    "# Provide training schedule of the model\n",
    "# When evaluationg intermediate steps the tranining schedule must be provided\n",
    "train_schedule = OrderedDict()\n",
    "if model_size == 'small':\n",
    "    train_schedule[1] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"heads\"}\n",
    "    train_schedule[120] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"4+\"}\n",
    "    train_schedule[160] = {\"learning_rate\": config.LEARNING_RATE/10, \"layers\": \"all\"}\n",
    "elif model_size == 'large':\n",
    "    train_schedule[1] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"heads\"}\n",
    "    train_schedule[240] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"all\"}\n",
    "    train_schedule[320] = {\"learning_rate\": config.LEARNING_RATE/10, \"layers\": \"all\"}\n",
    "\n",
    "# Select checkpoint\n",
    "if model_size == 'small':\n",
    "    checkpoint = 'checkpoints/small_siamese_mrcnn_0160.h5'\n",
    "elif model_size == 'large':\n",
    "    checkpoint = 'checkpoints/large_siamese_mrcnn_coco_full_0320.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "b73yjE6zUCaO",
    "outputId": "776353ec-bbf0-421c-b168-21ee536445ab"
   },
   "outputs": [],
   "source": [
    "# Load and evaluate model\n",
    "# Create model object in inference mode.\n",
    "model = siamese_model.SiameseMaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_checkpoint(checkpoint, training_schedule=train_schedule)\n",
    "# Evaluate only active classes\n",
    "active_class_idx = np.array(coco_val.ACTIVE_CLASSES) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HiFUSEjbl-_1",
    "outputId": "505ec33f-7426-499d-ab4a-9807992fdf1a"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for layer in model.keras_model.layers:\n",
    "  count += 1\n",
    "  if str(layer).find('Model') != -1:\n",
    "    print(count, str(layer))\n",
    "    break\n",
    "index = count - 1\n",
    "model.keras_model.layers[index].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aMddS9QTtQse",
    "outputId": "e6069499-181a-49b7-bf3c-3a076eeeb2f7"
   },
   "outputs": [],
   "source": [
    "filters, biases = model.keras_model.layers[index].layers[9].get_weights()\n",
    "\n",
    "filters_min, filters_max = filters.min(), filters.max()\n",
    "filters = (filters - filters_min)/(filters_max - filters_min)\n",
    "\n",
    "_, _, n_channels, n_filters = filters.shape\n",
    "\n",
    "n_channels = 16 #Can't visualise all filters and channels, hence 16 each\n",
    "n_filters = 16\n",
    "ind = 1\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (30,30)\n",
    "\n",
    "for i in range(n_filters):\n",
    "  f = filters[:, :, :, i]\n",
    "  for j in range(n_channels):\n",
    "    ax = plt.subplot(n_filters, n_channels, ind)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.imshow(f[:, :, j], cmap= 'viridis')\n",
    "    ind += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wNA7v06gIyA"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "from keras.models import Model\n",
    "indexes = [17,27,37,49,59,69,79,91,101,111,121,131,141,153,163,173]\n",
    "outputs = [model.keras_model.layers[index].layers[i].output for i in indexes]\n",
    "model_feature_maps = Model(inputs=model.keras_model.layers[index].inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "NMWPMD-T3QST",
    "outputId": "ae809981-0570-4dc1-8aba-c0026e47db4e"
   },
   "outputs": [],
   "source": [
    "# Select category\n",
    "category = 1\n",
    "np.random.seed(7)\n",
    "image_id = np.random.choice(coco_val.category_image_index[category])   \n",
    "# Load target\n",
    "target = siamese_utils.get_one_target(category, coco_val, config)\n",
    "# Load image\n",
    "image = coco_val.load_image(image_id)\n",
    "img = np.expand_dims(image, axis=0)\n",
    "feature_maps = model_feature_maps.predict(img)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "K-qgqbPfxJJr",
    "outputId": "c8a80a11-406f-4314-bfc4-b4e3d9a549eb"
   },
   "outputs": [],
   "source": [
    "feature_maps = model_feature_maps.predict(img)\n",
    "# plot the output from each block\n",
    "square = 2\n",
    "s = f\"\"\"\\n\"\"\"\n",
    "for fmap in feature_maps:\n",
    "  # plot 64 maps for first 3 layers\n",
    "  ix = 1\n",
    "  for _ in range(square):\n",
    "    for _ in range(square):\n",
    "      \n",
    "      # specify subplot\n",
    "      ax = plt.subplot(square, square, ix)\n",
    "\n",
    "      # plot filter channel \n",
    "      plt.imshow(fmap[0, :, :, ix-1], cmap='viridis')\n",
    "      ix += 1\n",
    "\n",
    "  plt.text(0,64,s)\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NNFL_Project_Code",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
