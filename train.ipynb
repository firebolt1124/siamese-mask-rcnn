{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnqbp4wsnYu8"
      },
      "source": [
        "!pip uninstall tensorflow \n",
        "!pip install tensorflow-gpu==1.14\n",
        "\n",
        "!pip uninstall keras \n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYL7pKkrna1J"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "#%load_ext line_profiler\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "sess_config = tf.ConfigProto()\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "COCO_DATA = 'data/coco'\n",
        "MASK_RCNN_MODEL_PATH = 'lib/Mask_RCNN/'\n",
        "\n",
        "if MASK_RCNN_MODEL_PATH not in sys.path:\n",
        "    sys.path.append(MASK_RCNN_MODEL_PATH)\n",
        "    \n",
        "from lib.Mask_RCNN.samples.coco import coco\n",
        "from lib.Mask_RCNN.mrcnn import utils\n",
        "from lib.Mask_RCNN.mrcnn import model as modellib\n",
        "from lib.Mask_RCNN.mrcnn import visualize\n",
        "    \n",
        "from lib import utils as siamese_utils\n",
        "from lib import model as siamese_model\n",
        "from lib import config as siamese_config\n",
        "   \n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import imgaug\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# train_classes = coco_nopascal_classes\n",
        "train_classes = np.array(range(1,81))\n",
        "\n",
        "# Load COCO/val dataset\n",
        "coco_val = siamese_utils.IndexedCocoDataset()\n",
        "coco_object = coco_val.load_coco(COCO_DATA, \"val\", year=\"2017\",return_coco=True)\n",
        "coco_object.getCatIds()\n",
        "coco_val.prepare()\n",
        "coco_val.build_indices()\n",
        "coco_val.ACTIVE_CLASSES = train_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN7whOn32p1L"
      },
      "source": [
        "class SmallTrainConfig(siamese_config.Config):\n",
        "    # Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 6 # A 16GB GPU is required for a batch_size of 12\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    NAME = 'small_coco'\n",
        "    EXPERIMENT = 'example'\n",
        "    CHECKPOINT_DIR = 'checkpoints/'\n",
        "    STEPS_PER_EPOCH = 4   # changed this to reduce load from 1000 to 4\n",
        "    VALIDATION_STEPS = 1  # changed this from its og value in config\n",
        "    # Adapt loss weights\n",
        "    LOSS_WEIGHTS = {'rpn_class_loss': 2.0, \n",
        "                    'rpn_bbox_loss': 0.1, \n",
        "                    'mrcnn_class_loss': 2.0, \n",
        "                    'mrcnn_bbox_loss': 0.5, \n",
        "                    'mrcnn_mask_loss': 1.0}\n",
        "    \n",
        "class LargeTrainConfig(siamese_config.Config):\n",
        "    # Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 4\n",
        "    IMAGES_PER_GPU = 3 # 4 16GB GPUs are required for a batch_size of 12\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    NAME = 'large_coco'\n",
        "    EXPERIMENT = 'example'\n",
        "    CHECKPOINT_DIR = 'checkpoints/'\n",
        "    # Reduced image sizes\n",
        "    TARGET_MAX_DIM = 192\n",
        "    TARGET_MIN_DIM = 150\n",
        "    IMAGE_MIN_DIM = 800\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "    # Reduce model size\n",
        "    FPN_CLASSIF_FC_LAYERS_SIZE = 1024\n",
        "    FPN_FEATUREMAPS = 256\n",
        "    # Reduce number of rois at all stages\n",
        "    RPN_ANCHOR_STRIDE = 1\n",
        "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
        "    POST_NMS_ROIS_TRAINING = 2000\n",
        "    POST_NMS_ROIS_INFERENCE = 1000\n",
        "    TRAIN_ROIS_PER_IMAGE = 200\n",
        "    DETECTION_MAX_INSTANCES = 100\n",
        "    MAX_GT_INSTANCES = 100\n",
        "    # Adapt NMS Threshold\n",
        "    DETECTION_NMS_THRESHOLD = 0.5\n",
        "    # Adapt loss weights\n",
        "    LOSS_WEIGHTS = {'rpn_class_loss': 2.0, \n",
        "                    'rpn_bbox_loss': 0.1, \n",
        "                    'mrcnn_class_loss': 2.0, \n",
        "                    'mrcnn_bbox_loss': 0.5, \n",
        "                    'mrcnn_mask_loss': 1.0}\n",
        "\n",
        "# The small model trains on a single GPU and runs much faster.\n",
        "# The large model is the same we used in our experiments but needs multiple GPUs and more time for training.\n",
        "model_size = 'small' # or 'large'\n",
        "\n",
        "if model_size == 'small':\n",
        "    config = SmallTrainConfig()\n",
        "elif model_size == 'large':\n",
        "    config = LargeTrainConfig()\n",
        "    \n",
        "config.display()\n",
        "\n",
        "# Create model object in inference mode.\n",
        "model = siamese_model.SiameseMaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxW5Dc7L1mv3"
      },
      "source": [
        "# train_schedule = OrderedDict()\n",
        "# train_schedule[1] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"heads\"}\n",
        "# train_schedule[120] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"all\"}\n",
        "# train_schedule[160] = {\"learning_rate\": config.LEARNING_RATE/10, \"layers\": \"all\"}\n",
        "\n",
        "# We commented out the above as google colab kept crashing, so we reduced the load\n",
        "# Check if both folders under 'logs' folder are empty before running model.train\n",
        "train_schedule = OrderedDict()\n",
        "train_schedule[1] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"heads\"}\n",
        "train_schedule[3] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"all\"}\n",
        "\n",
        "# Load weights trained on Imagenet\n",
        "try: \n",
        "    model.load_latest_checkpoint(training_schedule=train_schedule)\n",
        "except:\n",
        "    model.load_imagenet_weights(pretraining='imagenet-687')\n",
        "l = []\n",
        "for epochs, parameters in train_schedule.items():\n",
        "    print(\"\")\n",
        "    print(\"training layers {} until epoch {} with learning_rate {}\".format(parameters[\"layers\"], \n",
        "                                                                          epochs, \n",
        "                                                                          parameters[\"learning_rate\"]))\n",
        "    history = model.train(coco_val, coco_val, \n",
        "                learning_rate=parameters[\"learning_rate\"], \n",
        "                epochs=epochs, \n",
        "                layers=parameters[\"layers\"])\n",
        "\n",
        "print(\"Training completed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gY4tOuop1vA"
      },
      "source": [
        "## Plot the losses\n",
        "plt.rcParams[\"figure.figsize\"] = (7,5)\n",
        "a= plt.figure()\n",
        "plt.plot(range(1,epochs), history.history['val_loss'], 'r', label = 'Test Loss')\n",
        "plt.plot(range(1,epochs), history.history['loss'], 'y', label = 'Train Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('/content/drive/MyDrive/siamese-mask-rcnn-master/train_plot.jpg')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
